<html>

  <head>
    <link rel="stylesheet"  type="text/css" href="css/help.css">
  </head>

  <body>
    <a name="local_adaptive_threshold_globloc"></a>
    <a name="primary4"></a>    
    <h2>Global and Local Adaptive Threshod, Split by morphological dynamics</h2>
    <p class="text">
      Performs object detection based on global and local adaptive thresholding.       
      A background map of the input image is computed based on the <i>Window size</i> (moving average window).             
      An image pixel is considered an object pixel if its value is higher than <i>Min. contrast</i> than the background, 
      or if it has been selected by the Otsu method (see below). The combination is often useful, if the nuclei are dense, but
      it has its limitations if the nuclei show large intensity variations or if the background is not uniformly illuminated. 
      Therefore, this plugin works well for DAPI staining and dense populations. Note that even though both global and local 
      thresholding is optional, it cannot work if neither of the methods is selected.  
      In order to enhance the results, there are a number of prefiltering techniques that can be applied in addition (see below).
    </p>
    
    
    <a name="togglemappings"></a>
    <h4>Toggle Mappings</h4>
    <p class="text">
      Toggle mappings allow to sharpen images by mathematical morphology. This sharpening then leads to less cases of joint segmentation of cell nuclei: it helps in separating nuclei without a prior on the shape of the detected objects. However, if there is no decrease in the signal between two nuclei, this method will not help. 
    </p>
    
    <a name="tm_size"></a>
    <h4 class="sub">Size of the structuring element used by Toggle Mappings</h4>
    <p class="subtext">
    In this implementation, Toggle Mappings (TM) calculate an erosion and a dilation with a structuring element of user-defined size. The operator then assigns to each pixel the value of erosion or dilation depending on which of the two is closer to the initial pixel value. This parameter defines the size of the erosion and dilation.  
    </p>
    
    <a name="medianradius"></a>
    <h4>Median radius</h4>
    <p class="text">
      The median filter removes noise, while keeping the edges intact (no blurring of the image). The degree of filtering is controlled by the radius of the median filter (radius measured in pixels: the higher the value, the stronger the filter). Note: Filtered image is used for object detection only (no influence on feature extraction, but shape features might be affected). Note also that the parameter scales directly with lens magnification.
    </p>

    <a name="local"></a>
    <h4>Local Threshold</h4>
    <p class="text">
    Determines whether a local threshold will be applied. The local threshold corresponds to a threshold of the background subtracted image. 
    </p>

    <a name="latwindowsize"></a>
    <h4 class="sub">Window size</h4>
    <p class="subtext">
      Window size of squared window for the moving average in pixels. This parameter scales with lens magnification.
    </p>

    <a name="latlimit"></a>
    <h4 class="sub">Min. contrast</h4>
    <p class="subtext">Pixel intensity above the background (threshold, applied on the difference between image and locally averaged image). Note: Small values might increase artifacts (small objects from high noise levels) and slow down computation; high values might lead to incorrect contours and also leads to fewer objects, as dark objects will not be detected.
    </p>


    <a name="latlimit"></a>
    <h4 class="sub">Min. contrast</h4>
    <p class="subtext">Pixel intensity above the background (threshold, applied on the difference between image and locally averaged image). Note: Small values might increase artifacts (small objects from high noise levels) and slow down computation; high values might lead to incorrect contours and also leads to fewer objects, as dark objects will not be detected.
    </p>

    <a name="global"></a>
    <h4>Global Threshold</h4>
    <p class="text">
    Determines whether a global threshold will be applied. Here, global threshold corresponds to the well known Otsu threshold.
    The Otsu threshold is the threshold that minimizes intra-object and intra-background variance. It is therefore a non-parametric method. 
    In practice, the user often wants to adjust this threshold. Therefore, the applied threshold is calculated from the optimal threshold by
    multiplication of the user-defined Otsu Factor and addition of the user-defined offset, i.e. it o is the Otsu threshold, and a and b the 
    user-defined factor and offset respectively, the final threshold is a * o + b. For a=1.0 and b=0.0, we obtain the original Otsu method. 
    </p>

    <a name="otsu_factor"></a>
    <h4 class="sub">Otsu Factor</h4>
    <p class="subtext"> User-defined Otsu-factor a. The final threshold is a * o + b. 
    </p>

    <a name="offset"></a>
    <h4 class="sub">Otsu Offset</h4>
    <p class="subtext"> User-defined Otsu-factor a. The final threshold is a * o + b.
    </p>

    <a name="watershed_distance"></a>
    <h4>Watershed (distance)</h4>
    <p class="text">
      Optional correction of under-segmentation, based on the well-known watershed approach: 
      An inverse distance map of the initial segmentation is calculated, and the final split is achieved by application of the watershed transform.
      The minima from which the flooding is initiated are selected by morphological dynamics; losely speaking, this corresponds to the depth of the minimum. 
      Here, we have developed a method which does the minima selection and the watershed transformation in a single step, which is particularly fast.
    </p>

    <a name="watershed_dynamic"></a>
    <h4 class="sub">Minimal Depth</h4>
    <p class="subtext">
      The depth of a minimum allowed to generate a single object. Higher values lead to less objects, as more splits are rejected.
    </p>

    <a name="watershed_used_distance"></a>
    <h4 class="sub">Distance metric</h4>
    <p class="subtext">
      This is the distance metric used by the watershed algorithm. 0 corresponds to 4-connectivity, 1 corresonds to 8-connectivity and 2 to usual Euclidean distance.
      We have observed that 2 is generally the best value. 
    </p>

    <a name="holefilling"></a>
    <h4>Fill holes</h4>
    <p class="text">
       Remove holes from foreground ojbects. The standard procedure would remove all holes from the detected objects. The definition of a hole is a connected component of the background, which cannot be reached from the image border. If cells are dense, the space enclosed by several cells would therefore also be removed. Here, we only remove holes of a certain size.
    </p>
    
    <a name="holearea"></a>
    <h4 class="sub">Maximal Hole Size</h4>
    <p class="subtext">
    Determines the number of pixels up to which a "hole" (connected component of the background disconnected from the background) is considered as a hole inside an object.   
    </p>
    
    <a name="removeborderobjects"></a>
    <h4 class="sub">Remove border objects</h4>
    <p class="subtext">
      Filter out all foreground objects that touch the image border.
    </p>

    <a name="postprocessing"></a>
    <h4>Object filter</h4>
    <p class="text">
      Optional object filtering based on size and intensity. To specify a lower of upper bound only enter the value <tt>-1</tt>.
    </p>

    <a name="postprocessing_roisize_min"></a>
    <h4 class="sub">Min. object size</h4>
    <p class="subtext">
      All objects below that size (pixel) are removed. This parameter scales with squared lens magnificaiton.
    </p>

    <a name="postprocessing_roisize_max"></a>
    <h4 class="sub">Max. object size</h4>
    <p class="subtext">
      All objects above that size (pixel) are removed. This parameter scales with squared lens magnification.
    </p>

    <a name="postprocessing_intensity_min_above_bg"></a>
    <h4 class="sub">Min. average intensity above background</h4>
    <p class="subtext">
      From the segmentation result, the average intensity of the background is calculated. 
      If the difference of the average intensity inside the object and the average background intensity is below the user defined value, the object is removed.    
      This filter does not work well in case of non-uniform illumination, but it is robust to intensity offsets. 
    </p>

    <a name="postprocessing_intensity_max_above_bg"></a>
    <h4 class="sub">Max. average intensity above background</h4>
    <p class="subtext">
      From the segmentation result, the average intensity of the background is calculated. 
      If the difference of the average intensity inside the object and the average background intensity is above the user defined value, the object is removed.    
      This filter does not work well in case of non-uniform illumination, but it is robust to intensity offsets. 
    </p>

  </body>
</html>
