<html>
<head>
<link rel="stylesheet"  type="text/css" href="help.css">
</head>
<body>

<!-- HEADER -->

<h1>Output</h1>
<p>
Processing results like contour images for annotation by <img class="extlink" src=":extlink"/><a href="http://rsbweb.nih.gov/ij/">ImageJ</a>'s CellCounter or label images for further (external) processing can be written to file. Measured values for follow-up statistics like object data including features over the entire movie or along trajectories, or counts of class labels can be exported to text files compatible with e.g. Excel or Prism.
</p>
<hr></hr>

<h3>CellH5 output</h3>
Generated CellH5 hdf5 files as described in <a href="http://www.ncbi.nlm.nih.gov/pubmed/23595665"><b>CellH5: a format for data exchange in high-content screening.</b></a>

<h4>Create HDF5</h4>

<a name="hdf5_include_raw_images">
<h4 class="sub">Include 8-bit image data</h4>
<p class="subtext">Store the normalized raw images</p>
</a>

<a name="hdf5_include_label_images">
<h4 class="sub">Include segmentation images</h4>
<p class="subtext">Store the segmentation as label images</p>
</a>

<a name="hdf5_include_crack">
<h4 class="sub">Include crack contours</h4>
<p class="subtext">Store the segmentation as contours (needed for segmentation overlays of outlines)</p>
</a>

<a name="hdf5_include_features">
<h4 class="sub">Include features</h4>
<p class="subtext">Include the features computed for every channel and region</p>
</a>

<a name="hdf5_include_classification">
<h4 class="sub">Include classification</h4>
<p class="subtext">Include the classification of each object with its color and class name</p>
</a>

<a name="hdf5_include_tracking">
<h4 class="sub">Include tracking</h4>
<p class="subtext">Include the full tracking of all objects</p>
</a>

<a name="hdf5_include_events">
<h4 class="sub">Include events</h4>
<p class="subtext">Include events as separate CellH5 objects as sub-trajectories of the full tracking (tracking is required)</p>
</a>

<a name="hdf5_compression">
<h4 class="sub">Enable gzip compression</h4>
<p class="subtext">Use compression (recommended)</p>
</a>

<a name="hdf5_merge_positions">
<h4 class="sub">Merge CellH5 position files</h4>
<p class="subtext">Merge CellH5 position files into one entry file (_all_positions.ch5)</p>
</a>

<h4>Reuse HDF5</h4>

<a name="hdf5_reuse">
<h4 class="sub">Enable this feature if you want use precomputed raw and segmentation images (as stored in the CellH5 files) Note that, changes in the object detection and gray value normalization will have no effect if enabled!</h4>
</a>

<a name="minimal_effort">
  <h4>Only necessary steps</h4>
  <p class="text">If this option is selected in addition to Reuse
  HDF5, CellCognition analyzer will only execute the analysis steps
  defined in the Processing tab and try to read the necessary
  information from the HDF5 file. In particular, it is possible to
  avoid segmentation, if the features are already calculated. This
  option is not recommended for interactive use (as segmentation is
  required for visualization). If Reuse HDF5 is not selected, this
  option has no effect. 
  </p>
</a>


<h3>Text file output</h3>
<b>Text output is deprecated and will be removed in future releases!</b>
<a name="export_result_images">
<h4>Export result images</h4>
<p class="text">Result images like contour overlays or label images (containing segmentation for further processing) can be written to disc during processing.

<a name="rendering_labels_discwrite">
<h4 class="sub">Label images</h4>
<p class="subtext">Export label images. Image format: 16bit TIFF encoding object IDs.</p>
</a>

<a name="rendering_contours_discwrite">
<h4 class="sub">Contour images</h4>
<p class="subtext">Contour overlay images for the primary channel, all enabled regions of the secondary channel, and tracking. Colors correspond to the different regions. Image format: 8bit JPEG.</p>
</a>

<a name="rendering_contours_showids">
<h4 class="sub">Show object IDs</h4>
<p class="subtext">Object IDs are shown in the contour images. The IDs correspond to the label images and the statistical output below. Note that object IDs change over time for the same object!</p>
</a>

<a name="rendering_class_discwrite">
<h4 class="sub">Classification images</h4>
<p class="subtext">Contour overlay images for the classification results for the primary channel and classified region of the secondary channel. Colors correspond to the predicted class label. Image format: 8bit JPEG.</p>
</a>

<a name="rendering_class_showids">
<h4 class="sub">Show object IDs</h4>
<p class="subtext">Object IDs are shown in the classification
  images. The IDs correspond to the label images and the statistical
  output below. Note that object IDs change over time for the same
  object!</p>

<a name="rendering_channel_gallery">
<h4 class="sub">Merged channel gallery</h4>
<p class="subtext">A merged channel gallery image shows the objects
  (cells) of the selected channels beside each other. The subimages
  are ordered from left to right, starting with the image extracted
  from the primary channel, then from secondary and tertiary
  channel, if selected. In the last subimage all previous channels are
  merged together to an color image. <br>
  Further the crack contours of the segemented
  regions are drawn in the color of the corresponding class label. If
  classification was turned off for a certain channel, the color of the
  crack contour is white. Since there is no crack countour in the
  merged channel, the image shows the contour of the primary channel,
  but uses the class color of the merged channel.</p>
</a>
</p>
</a>

<a name="statistics">
<h4>Statistics</h4>
<p class="text">Measurements per object for the entire movie or along trajectories as well as summarized object and class counts can be exported as text files. All files in this section are located in the <tt>statistics</tt> sub-folder of a movie in the output folder (see structure of the output-folder in <a href="qrc:/general#pathout">General</a>).

<a name="export_object_counts">
<h4 class="sub">Export object counts</h4>
<p class="subtext">Exports the number of objects per frame in one file per movie. If classification is enabled the number of objects per class for the primary and secondary channel are included.</p>
</a>

<a name="export_object_details">
<h4 class="sub">Export detailed object data</h4>
<p class="subtext">Detailed object information like ID, class label, class probabilities, features (only intensity average and standard deviation for now), and centroid x/y coordinated are written to one file per movie.</p>
</a>

<a name="export_track_data">
<h4 class="sub">Export track data</h4>
<p class="subtext">A simple way to export a layered graph structure, which is the result of cell tracking, is the export of all possible full trajectories. Every trajectory without a previous node (in-degree=0) is written to one file. In case of a trajectory split (out-degree>1) a new file is created with increasing <tt>Bxx</tt> in the filename, where <tt>xx</tt> encode the n<sup>th</sup> branch of that trajectory. Merge events are <b>not</b> considered by this kind of export.
<br/>Full trajectories files are located in the sub-folder <tt>full</tt>. Their purpose is mainly a semi-automatic analysis, e.g. to obtain intensity kinetics.
<br/>Filename tokens are separated by double underscores <tt>__</tt> and are encoded the way:
<ul>
<li><tt>Pxxxxx</tt> - the position/movie name; <tt>xxxxx</tt> is a string</li>
<li><tt>Txxxxx</tt> - the frame/time-point; <tt>xxxxx</tt> is a positive number</li>
<li><tt>Oxxxx</tt> - the object ID the file is referring to. <tt>xxxx</tt> is a positive number starting at 1.</li>
<li><tt>Bxx</tt> - the trajectory branch. <tt>xx</tt> is a positive number starting at 1.</li>
</ul>
Example: The filename <tt>P0034__T00100__O0333__B03</tt> would therefore refer to a trajectory of movie <i>0034</i> starting at time-point <i>100</i> at the object with ID <i>333</i>. The file contains data about the 3<sup>rd</sup> branch, indicating that 2 splits have occured before.
</p>
</a>
</p>
</a>

<!-- FOOTER -->

</body>
</html>
